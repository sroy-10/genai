{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjrm3x8D3b+N45Jnlibfxc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sroy-10/genai/blob/main/LangChain/Langchain_v03_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xf1tWibkevst"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "print(langchain.__version__)"
      ],
      "metadata": {
        "id": "RnN5PpQek9Qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"var.env\")"
      ],
      "metadata": {
        "id": "Rw2DVmQmnRkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Azure OpenAI"
      ],
      "metadata": {
        "id": "9eIj2zYbmYas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import AzureChatOpenAI\n",
        "\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.environ[\"AZ_API_KEY\"]\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv(\"AZ_BASE\") # https://YOUR-ENDPOINT.openai.azure.com/\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    azure_deployment=os.getenv(\"AZ_MODEL\"),\n",
        "    api_version=os.getenv(\"AZ_API_VERSION\"),\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")\n",
        "\n",
        "messages = [\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
        "    ),\n",
        "    (\"human\", \"I love programming.\"),\n",
        "]\n",
        "\n",
        "ai_msg = llm.invoke(messages)\n",
        "ai_msg"
      ],
      "metadata": {
        "id": "OUNa9rrilWTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = llm.invoke(\"What is the capital of India?\")\n",
        "result.content"
      ],
      "metadata": {
        "id": "TgQ_uIgSpGTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hugging Face Endpoints"
      ],
      "metadata": {
        "id": "ycBQcu894GaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
        "\n",
        "# environment variable should be named as HUGGINGFACEHUB_API_TOKEN\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"microsoft/Phi-3-mini-4k-instruct\",\n",
        "    # repo_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", # error was coming with this repo\n",
        "    task=\"text-generation\",\n",
        "    max_new_tokens=512,\n",
        "    do_sample=False,\n",
        "    repetition_penalty=1.03,\n",
        ")\n",
        "\n",
        "chat = ChatHuggingFace(llm=llm, verbose=True)\n",
        "print(chat.invoke(\"What is the capital of India??\").content)\n",
        "\n",
        "\n",
        "messages = [\n",
        "    (\"system\", \"You are a helpful translator. Translate the user sentence to French.\"),\n",
        "    (\"human\", \"I love programming.\"),\n",
        "  ]\n",
        "\n",
        "print(chat.invoke(messages).content)"
      ],
      "metadata": {
        "id": "1l30mWKS5Bi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hugging Face Local (Model will be downloaded in local)"
      ],
      "metadata": {
        "id": "qq63Ci6o-lQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
        "\n",
        "# incase the model needs to be downloaded to other local drives instead of c:\n",
        "# import os\n",
        "# os.environ['HF_HOME'] = 'D:/huggingface_cache'\n",
        "\n",
        "llm = HuggingFacePipeline.from_model_id(\n",
        "                    model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
        "                    task = \"text-generation\",\n",
        "                    pipeline_kwargs=dict(\n",
        "                            temperature=0.5,\n",
        "                            max_new_tokens=512,\n",
        "                            do_sample=False,\n",
        "                            repetition_penalty=1.03,\n",
        "                    ),\n",
        "                  )\n",
        "\n",
        "model = ChatHuggingFace(llm=llm)\n",
        "model.invoke(\"what is the capital of India?\").content"
      ],
      "metadata": {
        "id": "5qlD-Hsh-Ko-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Model - OpenAi"
      ],
      "metadata": {
        "id": "tS2puTuVA0dS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Single Document"
      ],
      "metadata": {
        "id": "v0CriBzPCKCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "embedding = OpenAIEmbeddings(model = 'text-embedding-3-large', diemnsion = 32)\n",
        "result = embedding.embed_query(\"New Delhi is the capital of India\")\n",
        "print(str(result))"
      ],
      "metadata": {
        "id": "zLK9xUnI_b6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Multiple Documents"
      ],
      "metadata": {
        "id": "IBE3KxvaCMIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "document = [\n",
        "    \"New Delhi is the capital of India\",\n",
        "    \"Paris is the capital of France\"\n",
        "]\n",
        "embedding = OpenAIEmbeddings(model = 'text-embedding-3-large', diemnsion = 32)\n",
        "result = embedding.embed_documents(document)\n",
        "print(str(result))"
      ],
      "metadata": {
        "id": "S8WDX0JdB1B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Model - Hugging Face"
      ],
      "metadata": {
        "id": "HCBATMp3DHvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "embedding = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2')\n",
        "result = embedding.embed_query(\"New Delhi is the capital of India\")\n",
        "print(str(result))"
      ],
      "metadata": {
        "id": "DJtIDLqCCPpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEndpointEmbeddings\n"
      ],
      "metadata": {
        "id": "UblWE4xUC9y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Model Query"
      ],
      "metadata": {
        "id": "02euF2PaEqlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "documents = [\n",
        "    \"Virat Kohli is an Indian cricketer known for his aggressive batting and leadership.\",\n",
        "    \"MS Dhoni is a former Indian captain famous for his calm demeanor and finishing skills.\",\n",
        "    \"Sachin Tendulkar, also known as the 'God of Cricket', holds many batting records.\",\n",
        "    \"Rohit Sharma is known for his elegant batting and record-breaking double centuries.\",\n",
        "    \"Jasprit Bumrah is an Indian fast bowler known for his unorthodox action and yorkers.\"\n",
        "]\n",
        "query = 'tell me about kohli'\n",
        "\n",
        "embedding = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "document_embedding = embedding.embed_documents(documents)\n",
        "query_embedding = embedding.embed_query(query)\n",
        "\n",
        "similarity_score = cosine_similarity(X=[query_embedding], Y=document_embedding) # it needs 2d array\n",
        "similarity_score"
      ],
      "metadata": {
        "id": "ko1tN0H5EqDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(enumerate(similarity_score[0]))"
      ],
      "metadata": {
        "id": "a3cr3V2hGAeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index, score = sorted(list(enumerate(similarity_score[0])), key=lambda x: x[1], reverse=True)[0]\n",
        "index, score"
      ],
      "metadata": {
        "id": "JTy254juFl3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"User → \", query)\n",
        "print(\"Assistant → \", documents[index])\n",
        "print(\"Score →\", score)"
      ],
      "metadata": {
        "id": "3r-eVqCDFzDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4R4RlN9xGRzQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}